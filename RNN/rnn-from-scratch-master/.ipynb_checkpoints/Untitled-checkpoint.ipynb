{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from rnn import RNN\n",
    "from data import train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "2113\n"
     ]
    }
   ],
   "source": [
    "papers = pd.read_csv('T.csv')\n",
    "papers = papers.drop(columns=['UserName', 'ScreenName', 'TweetAt','Location','Sentiment'], axis=1).sample(100)\n",
    "\n",
    "import re\n",
    "papers['OriginalTweet'] = \\\n",
    "papers['OriginalTweet'].map(lambda x: re.sub('[,\\.!?\\n\\rÂ’/n]', '', x))\n",
    "# Convert the titles to lowercase\n",
    "papers['OriginalTweet'] = \\\n",
    "papers['OriginalTweet'].map(lambda x: x.lower())\n",
    "# Print out the first rows of papers\n",
    "# print(papers['OriginalTweet'])\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "additional_words = ['from', 'subject', 're', 'edu', 'use','of','to','it','for','we','got','on','pm','get','put']\n",
    "stop_words.extend(additional_words)\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "\n",
    "data = papers.OriginalTweet.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "data_words = remove_stopwords(data_words)\n",
    "data_words = np.concatenate(data_words)\n",
    "\n",
    "print(data_words)\n",
    "# vocab = data_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 unique words found\n",
      "[['not', 'worri', 'about', 'running', 'out', 'of', 'food', 'toilet', 'paper', 'waterbut', 'growing', 'increasingly', 'concerned', 'that', 'didn', 'stock', 'up', 'enough', 'on', 'cannabis', 'covid', 'coronavirus'], ['covid', 'in', 'people', 'only', 'worry', 'abt', 'health', 'bcs', 'state', 'took', 'care', 'fr', 'everything', 'job', 'food', 'etc', 'covid', 'in', 'people', 'are', 'more', 'worry', 'about', 'job', 'food', 'etc', 'panic', 'buying', 'on', 'this', 'is', 'institutional', 'strength', 'of', 'gov'], ['according', 'to', 'the', 'centers', 'for', 'disease', 'control', 'your', 'sanitizer', 'mix', 'must', 'be', 'at', 'least', 'alcohol', 'to', 'be', 'effectiveyour', 'regular', 'vodka', 'and', 'whiskey', 'are', 'too', 'wimpy', 'and', 'won', 'cut', 'it', 'for', 'quality', 'and', 'effective', 'sanitizers', 'contact', 'for', 'the', 'best', 'prices', 'in', 'town', 'handsanitizer', 'covid_'], ['video', 'conferencing', 'online', 'shopping', 'remote', 'work', 'crypto', 'wallets', 'vr', 'ebooks', 'classroom', 'digital', 'assistants', 'assets', 'tokenization', 'sto', 'it', 'their', 'time', 'shine', 'organizations', 'that', 'don', 'offer', 'these', 'options', 'will', 'have', 'to', 'rethink', 'face', 'face', 'is', 'so', 'covid', 'xtz', 'covid'], ['ontario', 'insists', 'there', 'plenty', 'of', 'food', 'as', 'shoppers', 'rush', 'to', 'stock', 'up', 'due', 'to', 'covid', 'https', 'tco', 'bdzvoii', 'bl'], ['sainsbury', 'give', 'the', 'elderly', 'the', 'first', 'hour', 'of', 'supermarket', 'trading', 'during', 'covid', 'sign', 'the', 'petition', 'https', 'tco', 'sqpmscmbgb', 'via', 'ukchange'], ['went', 'to', 'the', 'grocery', 'store', 'over', 'lunch', 'just', 'to', 'pickup', 'puppy', 'food', 'and', 'wow', 'thursday', 'afternoon', 'and', 'the', 'place', 'is', 'rammed', 'covid_', 'https', 'tco', 'rhlgzbaxh'], ['grocery', 'store', 'out', 'of', 'food', 'so', 'if', 'eated', 'soap', 'don', 'eat', 'it', 'bc', 'did', 'no', 'didn', 'covid_'], ['so', 'gop', 'covid', 'is', 'left', 'to', 'run', 'rampant', 'thru', 'the', 'us', 'causing', 'untold', 'economic', 'chaos', 'by', 'the', 'shutting', 'of', 'sports', 'schools', 'small', 'businesses', 'tours', 'flights', 'job', 'losses', 'health', 'crises', 'stock', 'food', 'shortagesall', 'so', 'that', 'jared', 'kushner', 'brother', 'can', 'make', 'money', 'this', 'is', 'on', 'you'], ['if', 'you', 'are', 'lucky', 'enough', 'to', 'be', 'sitting', 'at', 'home', 'with', 'enough', 'food', 'to', 'get', 'you', 'through', 'period', 'of', 'self', 'isolation', 'please', 'consider', 'donating', 'to', 'the', 'trusselltrust', 'to', 'help', 'those', 'who', 'couldn', 'stock', 'up', 'even', 'if', 'they', 'wanted', 'to', 'trusselltrust', 'foodbanks', 'coronavirus', 'covid'], ['the', 'coronavirus', 'is', 'doing', 'more', 'for', 'this', 'country', 'than', 'any', 'president', 'lowering', 'airline', 'prices', 'gas', 'prices', 'free', 'sick', 'days', 'from', 'work', 'school', 'amp', 'less', 'traffic', 'covid_', 'for', 'president', 'dont', 'forget', 'to', 'vote', 'all', 'emergencyubi', 'medicare', 'all', 'emergencyubi', 'emergencyubi', 'emergencyubi'], ['how', 'has', 'the', 'impacted', 'consumer', 'spend', 'across', 'airlines', 'cruise', 'lines', 'restaurants', 'food', 'delivery', 'and', 'more', 'see', 'our', 'just', 'published', 'report'], ['before', 'we', 'talk', 'about', 'food', 'covid', 'we', 'have', 'to', 'flatten', 'the', 'curve', 'and', 'everyone', 'has', 'to', 'do', 'their', 'part', 'follow', 'your', 'local', 'government', 'recommendations', 'this', 'too', 'shall', 'pass', 'don', 'panic', 'don', 'spread', 'mis', 'information', 'https', 'tco', 'cmvov', 'wer'], ['kzapponetd', 'dcyapress', 'what', 'is', 'the', 'story', 'with', 'creches', 'etc', 'that', 'continue', 'to', 'charge', 'full', 'prices', 'while', 'they', 'are', 'closed', 'but', 'not', 'pay', 'their', 'workers', 'will', 'the', 'gov', 'insist', 'on', 'fees', 'being', 'refunded', 'to', 'parents', 'asking', 'for', 'ish', 'friends', 'covid_'], ['elzmo', 'love', 'sunday', 'of', 'work', 'nice', 'chilled', 'out', 'and', 'lazy', 'day', 'not', 'today', 'tho', 'now', 'feel', 'have', 'to', 'go', 'and', 'stock', 'up', 'because', 'of', 'these', 'selfish', 'bastards', 'so', 'food', 'shop', 'it', 'is', 'panicshopping', 'coronavirus', 'https', 'tco', 'uhyd', 'dxigp'], ['sidhakuro', 'bhoowan', 'well', 'rice', 'is', 'new', 'and', 'worrying', 'here', 'in', 'the', 'us', 'it', 'is', 'so', 'far', 'limited', 'to', 'tissue', 'papers', 'and', 'hand', 'sanitizers', 'only', 'hope', 'it', 'won', 'come', 'to', 'food', 'panic', 'coronavirus', 'covid_'], ['me', 'coming', 'back', 'from', 'the', 'grocery', 'store', 'places', 'are', 'packed', 'man', 'covid_', 'coronavirus', 'https', 'tco', 'kosxqnzaer'], ['panic', 'food', 'buying', 'in', 'germany', 'due', 'to', 'coronavirus', 'has', 'begun', 'but', 'the', 'organic', 'is', 'left', 'behind', 'hamsterkauf', 'panic', 'buying', 'is', 'called', 'hamster', 'purchases', 'hamsterkaufe', 'in', 'german', 'taken', 'from', 'the', 'way', 'hamsters', 'stuff', 'their', 'cheeks', 'with', 'food', 'https', 'tco', 'ayqtllgw'], ['emptyshelves', 'at', 'our', 'local', 'grocery', 'store', 'https', 'tco', 'hrhpz', 'uth', 'viruscorona', 'houstontx', 'covid_'], ['work', 'in', 'supermarket', 'you', 'can', 'panic', 'buy', 'all', 'you', 'like', 'as', 'far', 'as', 'am', 'concerned', 'just', 'be', 'polite', 'and', 'apologise', 'if', 'you', 'bash', 'us', 'drop', 'stuff', 'on', 'us', 'and', 'it', 'not', 'our', 'fault', 'if', 'it', 'didn', 'come', 'in', 'the', 'delivery'], ['government', 'is', 'urging', 'ontarians', 'to', 'practise', 'normal', 'grocery', 'buying', 'habits', 'as', 'store', 'shelveshave', 'emptied', 'of', 'supplies', 'including', 'hand', 'sanitizer', 'toilet', 'paper', 'cleaning', 'supplies', 'and', 'drugs', 'amid', 'panicked', 'buying', 'spurred', 'by', 'the', 'covid', 'pandemic', 'https', 'tco', 'tejjd', 'dqu'], ['just', 'like', 'in', 'europe', 'italy', 'spain', 'amp', 'many', 'more', 'countrys', 'we', 'should', 'start', 'protecting', 'our', 'grocery', 'store', 'safeway', 'calmartnv', 'we', 'should', 'have', 'either', 'the', 'calistogapoa', 'sthelenaca', 'usnationalguard', 'securing', 'our', 'basic', 'food', 'needs', 'for', 'the', 'long', 'days', 'ahead', 'covid_', 'https', 'tco', 'hjjicgzx'], ['pm', 'will', 'be', 'addressing', 'the', 'nation', 'at', 'pm', 'later', 'do', 'not', 'panic', 'though', 'do', 'not', 'wipe', 'out', 'the', 'supermarket', 'again', 'covid_'], ['this', 'is', 'good', 'news', 'for', 'control', 'of', 'covid', 'but', 'this', 'will', 'create', 'an', 'incredible', 'strain', 'on', 'resources', 'for', 'families', 'without', 'sick', 'leave', 'and', 'food', 'insecure', 'children', 'contact', 'your', 'legislators', 'today', 'to', 'demand', 'assistance', 'for', 'these', 'families', 'johncornyn', 'tedcruz', 'jeffleach', 'angelapaxtontx', 'https', 'tco', 'qxyjqzgacs'], ['if', 'you', 'have', 'booked', 'ticket', 'to', 'an', 'event', 'as', 'part', 'of', 'package', 'holiday', 'you', 'will', 'be', 'offered', 'an', 'alternative', 'or', 'refund', 'by', 'your', 'travel', 'provider', 'if', 'it', 'has', 'been', 'cancelled', 'due', 'to', 'coronavirus', 'check', 'abta', 'consumer', 'amp', 'at', 'https', 'tco', 'oub', 'mnmrna', 'covid', 'https', 'tco', 'kmhjehs', 'jh'], ['some', 'calming', 'reassurance', 'and', 'alignment', 'from', 'our', 'governments', 'would', 'be', 'welcome', 'we', 'will', 'get', 'through', 'this', 'vegetarians', 'and', 'vegans', 'must', 'think', 'the', 'carnivore', 'have', 'gone', 'mad', 'this', 'supermarket', 'was', 'fully', 'stocked', 'yesterday', 'covid_', 'https', 'tco', 'jobd', 'tfoqr'], ['anyone', 'feel', 'like', 'covid_', 'is', 'just', 'massive', 'conspiracy', 'created', 'by', 'supermarket', 'chains', 'and', 'dry', 'goods', 'companies', 'as', 'ploy', 'to', 'increase', 'their', 'st', 'quarter', 'revenues'], ['realdonaldtrump', 'bring', 'attention', 'to', 'panic', 'shoppers', 'it', 'unnecessary', 'everyone', 'needs', 'food', 'and', 'toilet', 'paper', 'and', 'other', 'store', 'products', 'coronavirus'], ['popped', 'over', 'at', 'my', 'local', 'supermarket', 'it', 'zombie', 'land', 'not', 'sure', 'why', 'people', 'are', 'panicking', 'are', 'people', 'stacking', 'up', 'for', 'few', 'weeks', 'or', 'year', 'smh', 'hardly', 'any', 'milk', 'frozen', 'food', 'tins', 'meds', 'pasta', 'all', 'gone', 'in', 'effect', 'stock', 'crypto', 'market', 'crashing', 'interest', 'rates', 'to', 'zero'], ['completely', 'changed', 'my', 'outlook', 'on', 'covid', 'time', 'to', 'stock', 'up', 'on', 'canned', 'food', 'https', 'tco', 'oszkjx'], ['what', 'are', 'business', 'or', 'consumer', 'behaviors', 'that', 'may', 'change', 'permanently', 'due', 'to', 'covid', 'ex', 'remote', 'work', 'house', 'hunting', 'online', 'online', 'grocery', 'explain', 'your', 'reasoning', 'covid', 'coronavirus', 'covid', 'india'], ['these', 'infographics', 'help', 'put', 'things', 'to', 'perspective', 'seriously', 'do', 'not', 'go', 'out', 'and', 'buy', 'shit', 'in', 'bulk', 'and', 'avoid', 'chinese', 'food', 'don', 'panic', 'covid_', 'https', 'tco', 'vpnlaq', 'nsu'], ['grocery', 'store', 'workers', 'should', 'get', 'time', 'and', 'half', 'until', 'this', 'is', 'over', 'they', 'aren', 'paid', 'enough', 'for', 'black', 'friday', 'conditions', 'every', 'shift', 'coronavirus', 'ohiocoronavirus', 'panicbuyers', 'covid_'], ['fining', 'people', 'for', 'being', 'out', 'of', 'their', 'homes', 'out', 'good', 'reason', 'such', 'as', 'the', 'grocery', 'store', 'or', 'pharmacy', 'outbreak', 'tests', 'italy', 'limits', 'week', 'after', 'the', 'lockdown', 'began', 'covid_', 'coronavirus', 'https', 'tco', 'rx', 'cfug', 'sb', 'via', 'youtube'], ['stubhub', 'is', 'offering', 'of', 'cancelled', 'event', 'ticket', 'prices', 'toward', 'different', 'ticket', 'savvy', 'decision', 'many', 'customers', 'will', 'remember', 'after', 'this', 'covid_', 'business', 'ends'], ['this', 'could', 'be', 'all', 'the', 'work', 'of', 'china', 'and', 'russia', 'oil', 'prices', 'to', 'hurt', 'trump', 'it', 'not', 'like', 'these', 'communists', 'haven', 'killed', 'millions', 'of', 'their', 'own', 'people', 'for', 'political', 'reasons', 'before', 'realdonaldtrump', 'change', 'my', 'mind', 'covid_', 'covd', 'https', 'tco', 'pcrzh', 'um'], ['why', 'are', 'old', 'people', 'perusing', 'through', 'grocery', 'store', 'with', 'no', 'gloves', 'on', 'and', 'look', 'like', 'character', 'off', 'of', 'assassin', 'creed', 'make', 'it', 'make', 'sense', 'covid', 'https', 'tco', 'jvsxf'], ['thanks', 'to', 'factors', 'such', 'as', 'covid_', 'an', 'oil', 'crash', 'and', 'the', 'rand', 'dollar', 'exchange', 'rate', 'substantial', 'decline', 'in', 'sa', 'fuel', 'prices', 'is', 'on', 'the', 'cards', 'for', 'april', 'more', 'insight', 'here', 'https', 'tco', 'slfrpsmzf', 'https', 'tco', 'iqtbdio'], ['covid', 'not', 'even', 'that', 'deadly', 'but', 'yall', 'stock', 'piling', 'food', 'aids', 'been', 'leaving', 'mfs', 'doa', 'since', 'the', 'bet', 'them', 'condoms', 'shelves', 'full', 'though'], ['sephora', 'has', 'free', 'shipping', 'online', 'now', 'until', 'the', 'end', 'of', 'march', 'bc', 'ppl', 'are', 'probably', 'more', 'comfortable', 'shopping', 'online', 'instead', 'of', 'in', 'stores', 'due', 'to', 'covid'], ['isn', 'it', 'crazy', 'how', 'people', 'stock', 'up', 'on', 'toilet', 'paper', 'and', 'not', 'food', 'coronavirus', 'coronaoutbreak'], ['with', 'empty', 'shelves', 'in', 'almost', 'every', 'retail', 'grocery', 'and', 'drug', 'store', 'establishment', 'couldn', 'resist', 'posting', 'this', 'let', 'get', 'grip', 'people', 'coronavirus', 'covid_', 'pismo', 'beach', 'california', 'https', 'tco', 'bvovhn'], ['it', 'okay', 'we', 'll', 'all', 'be', 'fine', 'in', 'torbay', 'never', 'actually', 'realised', 'we', 'had', 'so', 'many', 'infectious', 'disease', 'experts', 'in', 'town', 'they', 'are', 'all', 'offering', 'their', 'knowledge', 'amp', 'expertise', 'on', 'various', 'local', 'spotted', 'fb', 'pages', 'too', 'covid_'], ['spy', 'go', 'out', 'and', 'stock', 'up', 'on', 'food', 'and', 'water', 'people', 'better', 'safe', 'than', 'sorry', 'spx', 'qqq', 'iwm', 'dji', 'aapl', 'tsla', 'fb', 'amzn', 'gs', 'jpm', 'bac', 'googl', 'spot', 'xle', 'ba', 'baba', 'uvxy', 'es_f', 'coronavirus', 'covid', 'coronaalert', 'breaking', 'trumpaddress', 'https', 'tco', 'up', 'cifff'], ['due', 'to', 'growing', 'concerns', 'around', 'covid', 'creemore', 'springs', 'is', 'taking', 'additional', 'steps', 'to', 'be', 'extra', 'vigilant', 'to', 'maintain', 'the', 'health', 'amp', 'well', 'being', 'of', 'staff', 'amp', 'customers', 'our', 'retail', 'store', 'remains', 'open', 'but', 'tours', 'are', 'currently', 'suspended', 'updates', 'will', 'be', 'provided', 'on', 'social', 'channels', 'https', 'tco', 'wki', 'eix', 'xn'], ['should', 'out', 'to', 'all', 'the', 'grocery', 'store', 'employees', 'who', 'stayed', 'friendly', 'and', 'calm', 'while', 'the', 'crowds', 'surged', 'around', 'them', 'today', 'covid_'], ['my', 'latest', 'forecast', 'coronavirus', 'impact', 'demand', 'to', 'jump', 'dramatically', 'for', 'rural', 'properties', 'near', 'to', 'urban', 'centres', 'as', 'citizens', 'become', 'aware', 'of', 'benefits', 'of', 'not', 'living', 'in', 'densely', 'populated', 'areas', 'where', 'disease', 'can', 'spread', 'more', 'rapidly', 'food', 'security', 'family', 'safety', 'isolation'], ['in', 'light', 'of', 'the', 'current', 'coronovirus', 'covid', 'situation', 'bhta', 'consumer', 'advice', 'leaflet', 'get', 'wise', 'to', 'hand', 'hygiene', 'is', 'an', 'excellent', 'guide', 'the', 'document', 'will', 'show', 'you', 'the', 'importance', 'and', 'step', 'by', 'step', 'of', 'how', 'to', 'wash', 'your', 'hands', 'download', 'now', 'click', 'here', 'gt', 'gt', 'https', 'tco', 'ffve', 'xdvq', 'https', 'tco', 'stk', 'oalu'], ['jamiegenevieve', 'can', 'you', 'please', 'sign', 'this', 'petition', 'regarding', 'opening', 'the', 'supermarkets', 'to', 'the', 'elderly', 'first', 'please', 'lots', 'of', 'love', 'https', 'tco', 'prshz', 'mqsg'], ['these', 'stores', 'are', 'closing', 'or', 'changing', 'hours', 'due', 'to', 'coronavirus', 'https', 'tco', 'ctcrechm', 'https', 'tco', 'fxrvqjhlz'], ['it', 'makes', 'me', 'sad', 'to', 'think', 'about', 'all', 'the', 'food', 'that', 'will', 'go', 'to', 'waste', 'after', 'the', 'dust', 'settles', 'around', 'covid_', 'and', 'people', 'start', 'throwing', 'out', 'the', 'food', 'they', 'panic', 'bought', 'please', 'use', 'everything', 'you', 'purchase', 'not', 'everyone', 'is', 'as', 'lucky', 'as', 'you', 'to', 'be', 'able', 'to', 'buy', 'ahead'], ['everyone', 'talking', 'about', 'and', 'the', 'food', 'at', 'the', 'grocery', 'store', 'but', 'this', 'is', 'the', 'line', 'at', 'sportsman', 'warehouse', 'to', 'purchase', 'gun', 'coronapocalypse', 'covid_', 'coronaoutbreak', 'https', 'tco', 'lkgznldt'], ['covid', 'panic', 'buying', 'hits', 'grocery', 'stores', 'across', 'canada', 'panicmode', 'please', 'stop', 'rushing', 'to', 'the', 'grocery', 'store', 'https', 'tco', 'wnqgdqadg'], ['am', 'happy', 'to', 'report', 'that', 'after', 'all', 'the', 'coronavirus', 'protocols', 'put', 'in', 'effect', 'yesterday', 'in', 'utah', 'created', 'buying', 'frenzy', 'at', 'the', 'grocery', 'store', 'life', 'sustaining', 'products', 'were', 'still', 'available', 'today', 'covid_', 'priorities', 'survival', 'amwriting', 'https', 'tco', 'qxrtaluuag'], ['trying', 'not', 'to', 'be', 'paranoid', 'about', 'the', 'coronavirus', 'but', 'admit', 'have', 'been', 'binging', 'prepper', 'videos', 'on', 'youtube', 'it', 'probably', 'wise', 'idea', 'for', 'all', 'of', 'us', 'to', 'stock', 'up', 'on', 'supplies', 'food', 'medicine', 'water', 'booze'], ['missouri', 'ag', 'sues', 'televangelist', 'for', 'advertising', 'silver', 'solution', 'as', 'cure', 'for', 'coronavirus', 'https', 'tco', 'wuffral', 'nw', 'https', 'tco', 'kaojafct'], ['daviec', 'brianstelter', 'thank', 'god', 'someone', 'is', 'worried', 'about', 'the', 'financials', 'dave', 'the', 'financials', 'pay', 'people', 'bills', 'put', 'food', 'on', 'the', 'table', 'many', 'people', 'rely', 'on', 'the', 'stock', 'market', 'for', 'their', 'retirement', 'income', 'and', 'yes', 'coronavirus', 'is'], ['it', 'in', 'the', 'morning', 'and', 'on', 'the', 'verge', 'of', 'knocking', 'out', 'but', 'part', 'of', 'me', 'is', 'curious', 'if', 'right', 'now', 'is', 'good', 'time', 'to', 'be', 'at', 'the', 'grocery', 'store', 'and', 'if', 'should', 'go', 'by', 'groceries', 'while', 'others', 'sleep', 'covid_', 'pandemic'], ['avoid', 'long', 'lines', 'and', 'shop', 'online', 'plus', 'free', 'shipping', 'for', 'prime', 'members', 'cleaning', 'supplies', 'gt', 'https', 'tco', 'ioqxowemvs', 'personal', 'care', 'products', 'gt', 'https', 'tco', 'itmvitshhr', 'beauty', 'products', 'gt', 'https', 'tco', 'csjtobncgw', 'shopping', 'affiliate', 'coronavirus', 'https', 'tco', 'plwqi', 'vryr'], ['he', 'is', 'using', 'companies', 'traded', 'on', 'the', 'stock', 'market', 'to', 'help', 'him', 'with', 'the', 'problem', 'to', 'boast', 'their', 'stock', 'prices', 'but', 'not', 'explaining', 'how', 'ppl', 'will', 'be', 'able', 'to', 'pay', 'for', 'testing', 'and', 'treatment', 'the', 'okie', 'doke', 'sad', 'symonedsanders', 'covid_', 'karaswisher'], ['if', 'you', 'can', 'consider', 'donating', 'food', 'time', 'money', 'to', 'your', 'local', 'foodbank', 'to', 'help', 'those', 'who', 'can', 'stock', 'up', 'for', 'selfisolation', 'firstlovefdn', 'does', 'ace', 'work', 'in', 'towerhamlets', 'to', 'support', 'our', 'most', 'vulnerable', 'neighbours', 'get', 'involved', 'here', 'https', 'tco', 'blnnidg', 'coronavirus', 'covid'], ['coronavirus', 'preparation', 'what', 'to', 'stock', 'up', 'on', 'https', 'tco', 'knxa', 'wuhancoronavius', 'chinavirus', 'cnn', 'tedlieu'], ['liquor', 'store', 'done', 'got', 'there', 'at', 'the', 'am', 'opening', 'and', 'we', 'were', 'on', 'line', 'wrapped', 'around', 'the', 'store', 'very', 'little', 'boxes', 'of', 'wine', 'left', 'big_loags', 'coronavirus', 'coronapocolypse', 'philly', 'philadelphia', 'wine', 'stockup'], ['just', 'returned', 'from', 'the', 'grocery', 'store', 'shelves', 'are', 'half', 'empty', 'no', 'toilet', 'paper', 'no', 'ground', 'beef', 'no', 'cleaning', 'supplies', 'and', 'lines', 'to', 'the', 'middle', 'of', 'the', 'aisles', 'with', 'all', 'registers', 'open', 'this', 'is', 'going', 'to', 'get', 'nuts', 'covid_'], ['saracarterdc', 'of', 'us', 'deaths', 'are', 'from', 'hospitals', 'in', 'washington', 'state', 'only', 'total', 'from', 'the', 'rest', 'of', 'the', 'country'], ['you', 'know', 'what', 'great', 'to', 'do', 'when', 'you', 're', 'in', 'the', 'grocery', 'store', 'shopping', 'for', 'the', 'apocalypse', 'stand', 'more', 'than', 'inches', 'from', 'the', 'person', 'you', 're', 'in', 'line', 'behind', 'it', 'really', 'wonderful', 'everyone', 'should', 'try', 'it', 'perhaps', 'even', 'inches', 'or', 'go', 'crazy', 'the', 'world', 'ending', 'coronavirus'], ['us', 'world', 'food', 'prices', 'fell', 'during', 'february', 'world', 'food', 'prices', 'declined', 'in', 'feb', 'for', 'the', 'first', 'time', 'in', 'four', 'months', 'due', 'to', 'sharp', 'fall', 'in', 'the', 'export', 'prices', 'of', 'vegetable', 'oils', 'partly', 'driven', 'by', 'fears', 'that', 'the', 'covid', 'outbreak', 'will', 'slow', 'global', 'demand', 'read', 'https', 'tco', 'vikmtz'], ['my', 'approach', 'to', 'the', 'covid', 'lockdown', 'in', 'norway', 'is', 'bit', 'different', 'than', 'everyone', 'else', 'apparently', 'they', 're', 'stocking', 'up', 'on', 'food', 'bought', 'paint', 'and', 'went', 'to', 'the', 'library', 'to', 'stock', 'up', 'on', 'books', 'for', 'the', 'kids', 'sadly', 'the', 'library', 'had', 'also', 'closed', 'down', 'due', 'to', 'coronavirus'], ['earnings', 'are', 'expected', 'to', 'be', 'heavily', 'impacted', 'by', 'coronavirus', 'with', 'steep', 'declines', 'in', 'commodity', 'prices', 'and', 'analysts', 'cutting', 'estimates', 'tdhillon', 'and', 'daveaurelio', 'analyse', 'the', 'data', 'https', 'tco', 'uhwftlx', 'trusteddata', 'refinitiv', 'covid', 'https', 'tco', 'afvlnl', 'zia'], ['president', 'trump', 'announced', 'that', 'the', 'us', 'is', 'now', 'stockpiling', 'our', 'strategic', 'oil', 'reserve', 'why', 'because', 'oil', 'is', 'on', 'sale', 'at', 'per', 'barrel', 'valuable', 'asset', 'being', 'sold', 'at', 'hugely', 'discounted', 'prices', 'are', 'there', 'other', 'deals', 'covid_', 'stockstowatch', 'markets', 'https', 'tco', 'vn', 'qx'], ['covid', 'is', 'causing', 'an', 'extreme', 'amount', 'of', 'panic', 'amp', 'people', 'are', 'going', 'out', 'amp', 'buying', 'everything', 'that', 'they', 'can', 'get', 'their', 'hands', 'on', 'this', 'is', 'we', 'all', 'need', 'to', 'calm', 'down', 'amp', 'step', 'back', 'amp', 'realize', 'that', 'tp', 'amp', 'clorox', 'wipes', 'will', 'not', 'expire', 'amp', 'go', 'bad', 'and', 'if', 'you', 'overbuy', 'food', 'then'], ['roxetera', 'think', 'everybodyme', 'going', 'crazy', 'about', 'it', 'stay', 'safe', 'and', 'https', 'tco', 'vtyug', 'better', 'you', 'stock', 'more', 'food', 'there', 'to', 'avoid', 'covid'], ['the', 'financial', 'amp', 'economic', 'impact', 'of', 'covid', 'closures', 'and', 'cancellations', 'will', 'effect', 'every', 'consumer', 'and', 'taxpayer', 'in', 'every', 'state', 'coronavirus'], ['who', 'going', 'to', 'want', 'to', 'go', 'to', 'the', 'grocery', 'store', 'in', 'few', 'weeks', 'when', 'hospitals', 'are', 'packed', 'amp', 'there', 'are', 'or', 'of', 'carriers', 'can', 'you', 'guarantee', 'the', 'bulk', 'of', 'store', 'employees', 'aren', 'going', 'to', 'get', 'sick', 'not', 'panicking', 'but', 'excuse', 'me', 'if', 'don', 'want', 'to', 'get', 'sick', 'or', 'spread', 'coronavirus', 'https', 'tco', 'agc', 'qmntb'], ['people', 'are', 'annoying', 'af', 'rt', 'daisyfuentes', 'went', 'to', 'the', 'supermarket', 'amp', 'like', 'to', 'remind', 'everyone', 'that', 'covid_', 'is', 'respiratory', 'disease', 'not', 'assitory', 'disease', 'please', 'stop', 'hoarding', 'the', 'toilet', 'paper', 'thanks'], ['find', 'out', 'how', 'you', 'can', 'protect', 'yourself', 'and', 'loved', 'ones', 'from', 'coronavirus'], ['if', 'no', 'one', 'buys', 'anything', 'other', 'than', 'what', 'we', 'need', 'to', 'survive', 'like', 'food', 'and', 'medicine', 'then', 'we', 'don', 'need', 'economy', 'or', 'the', 'stock', 'market', 'the', 'only', 'reason', 'they', 'are', 'there', 'is', 'so', 'greedy', 'people', 'can', 'play', 'monopoly', 'coronavirus', 'coronaoutbreak', 'covid', 'maralagovirus', 'coronials', 'covid'], ['australia', 'chief', 'medical', 'officer', 'questions', 'victorian', 'health', 'advice', 'to', 'stock', 'up', 'food', 'supplies', 'for', 'weeks', 'we', 'don', 'want', 'to', 'encourage', 'mass', 'panic', 'buying', 'but', 'it', 'would', 'be', 'sensible', 'to', 'have', 'days', 'coronavirusaus', 'insiders', 'https', 'tco', 'fjk', 'moj'], ['bet', 'the', 'same', 'idiots', 'who', 'voted', 'for', 'ford', 'are', 'the', 'ones', 'stock', 'piling', 'food', 'thanks', 'https', 'tco', 'myuebhxr'], ['just', 'little', 'sketch', 'inspired', 'by', 'the', 'insane', 'climate', 'of', 'retail', 'lately', 'in', 'light', 'of', 'all', 'the', 'panic', 'shopping', 'people', 'are', 'doing', 'crazy', 'stuff', 'at', 'the', 'store', 'work', 'at', 'toilet', 'paper', 'madness', 'corona', 'coronavirus', 'https', 'tco', 'qmtzyg', 'nz'], ['covid_', 'xmas', 'come', 'early', 'everywhere', 'closed', 'supermarket', 'shelves', 'empty', 'army', 'on', 'streets', 'coronaoutbreak', 'football', 'cancelled', 'for', 'one', 'month', 'coronovirusuk', 'families', 'can', 'be', 'together', 'for', 'month', 'fooddeliveries', 'soapandwater', 'marc', 'polomints', 'ranvir', 'amycolenews', 'shobnagulati'], ['never', 'underestimate', 'girl', 'who', 'can', 'do', 'solid', 'deep', 'lunge', 'when', 'youre', 'fighting', 'for', 'the', 'last', 'items', 'in', 'frenzied', 'supermarket', 'covid_'], ['coronavirus', 'walmart', 'answer', 'to', 'beating', 'online', 'shopping', 'sorry', 'amazon', 'you', 'can', 'touch', 'this'], ['here', 'some', 'more', 'egg', 'info', 'in', 'case', 'you', 'stocked', 'up', 'eggs', 'eggsadayrok', 'panicbuying', 'stockup', 'coronavirus', 'bestbuydate', 'protein', 'hardboiledeggs', 'freezeyoureggs', 'foodsafety', 'needtoknow', 'https', 'tco', 'ewiuxpel'], ['please', 'parents', 'if', 'uk', 'schools', 'close', 'because', 'of', 'covid_', 'it', 'doesn', 'mean', 'you', 'just', 'let', 'them', 'meet', 'up', 'with', 'all', 'school', 'friends', 'and', 'hang', 'around', 'shopping', 'centres', 'defeating', 'the', 'purpose', 'hopefully', 'schools', 'will', 'look', 'at', 'online', 'classes'], ['with', 'all', 'of', 'this', 'panic', 'shopping', 'amp', 'emptying', 'out', 'shelves', 'stores', 'who', 'are', 'capable', 'should', 'just', 'switch', 'over', 'to', 'online', 'ordering', 'pick', 'up', 'instead', 'for', 'the', 'time', 'being', 'that', 'would', 'help', 'out', 'tremendously', 'sure', 'no', 'coronavirus', 'walmart', 'target', 'samsclub', 'costco'], ['the', 'grocery', 'store', 'is', 'fucking', 'mad', 'house', 'right', 'now', 'remind', 'me', 'to', 'never', 'go', 'back', 'again', 'until', 'this', 'shit', 'dies', 'down', 'covid_'], ['pam', 'goes', 'to', 'loblaws', 'reflections', 'on', 'ottawa', 'panic', 'purchasing', 'just', 'got', 'back', 'from', 'the', 'grocery', 'store', 'and', 'wanted', 'to', 'share', 'some', 'reflections', 'and', 'things', 'noticed', 'disclaimer', 'am', 'not', 'healthcare', 'professional', 'zombie', 'apocalypse', 'expert', 'or', 'doomsday', 'prepper', 'covid_', 'ottawa'], ['we', 'could', 'have', 'as', 'many', 'as', 'of', 'the', 'world', 'population', 'infected', 'with', 'the', 'coronavirus', 'by', 'the', 'end', 'of', 'the', 'year', 'your', 'prayers', 'are', 'useless', 'only', 'science', 'will', 'come', 'to', 'the', 'rescue', 'if', 'this', 'does', 'happen', 'our', 'world', 'will', 'not', 'recover', 'for', 'years', 'stock', 'up', 'your', 'can', 'food', 'people', 'doomsdaybunker'], ['is', 'there', 'hashtag', 'for', 'helping', 'folks', 'who', 'weren', 'able', 'to', 'go', 'to', 'the', 'grocery', 'store', 'amp', 'get', 'carts', 'of', 'food', 'have', 'any', 'major', 'grocery', 'stores', 'spoken', 'on', 'helping', 'communities', 'amp', 'making', 'food', 'available', 'to', 'those', 'who', 'are', 'furloughed', 'going', 'pay', 'rn', 'covid_', 'coronavirus'], ['panic', 'everywhere', 'runs', 'on', 'food', 'toilet', 'paper', 'bleach', 'the', 'stock', 'market', 'if', 'the', 'virus', 'doesn', 'kill', 'you', 'your', 'savings', 'will', 'be', 'wiped', 'out', 'and', 'you', 'probably', 'won', 'have', 'job', 'this', 'response', 'is', 'needlessly', 'destructive', 'coronavirus', 'panic'], ['dear', 'folks', 'buying', 'pasta', 'chopped', 'tomatoes', 'and', 'bog', 'roll', 'won', 'protect', 'you', 'from', 'coronavirus', 'crazy', 'what', 've', 'just', 'witnessed', 'in', 'the', 'local', 'supermarket', 'absolute', 'fannies', 'coronaoutbreak', 'covid_'], ['madness', 'tammyredmond', 'so', 'cabal', 'unleashes', 'bioweapon', 'to', 'create', 'fear', 'amp', 'panic', 'msm', 'runs', 'with', 'it', 'forcing', 'ppl', 'to', 'horde', 'food', 'supplies', 'causing', 'schools', 'to', 'shutdown', 'and', 'initiating', 'lockdowns', 'nationwide', 'whitehouse', 'hijacks', 'and', 'will', 'issue', 'martial', 'law', 'under'], ['gov', 'aka', 'boris', 'says', 'supermarkets', 'can', 'deal', 'with', 'demand', 'for', 'food', 'esp', 'if', 'we', 'go', 'into', 'lockdown', 'supermarkets', 'he', 'ain', 'said', 'nothing', 'about', 'nothing', 'we', 'haven', 'had', 'any', 'discussion', 'yet', 'gov', 'aka', 'boris', 'carrying', 'on', 'supermarkets', 'are', 'ready', 'and', 'britain', 'is', 'ready', 'covid_', 'uk', 'covid_', 'https', 'tco', 'uq', 'uqhrxgn'], ['information', 'from', 'the', 'competition', 'and', 'consumer', 'protection', 'commission', 'ccpc', 'ccpcireland', 'for', 'those', 'with', 'package', 'holiday', 'bookings', 'covid', 'https', 'tco', 'tccl'], ['in', 'light', 'of', 'the', 'pandemic', 'have', 'moved', 'to', 'online', 'shopping', 'can', 'we', 'have', 'free', 'shipping', 'for', 'online', 'orders', 'please', 'coronavirus', 'onlineshopping'], ['switzerland', 'is', 'not', 'doing', 'enough', 'as', 'retail', 'post', 'banks', 'grocery', 'store', 'convenient', 'outlets', 'publ', 'transport', 'operate', 'as', 'normal', 'no', 'protection', 'of', 'their', 'workers', 'and', 'its', 'customers', 'meanwhile', 'the', 'covid', 'is', 'on', 'its', 'race', 'track', 'grunliberale', 'shouldn', 'popular', 'party', 'get', 'the', 'grit'], ['ragingrodent', 'hello', 'matt', 'as', 'covid', 'has', 'spread', 'we', 've', 'recently', 'seen', 'an', 'increase', 'in', 'people', 'shopping', 'online', 'some', 'of', 'our', 'delivery', 'promises', 'are', 'longer', 'than', 'usual', 'but', 'we', 're', 'working', 'around', 'the', 'clock', 'to', 'ship', 'items', 'as', 'quickly', 'as', 'we', 're', 'able', 'to', 'thank', 'you', 'for'], ['couldn', 'get', 'half', 'my', 'grocery', 'list', 'from', 'the', 'store', 'since', 'they', 're', 'out', 'of', 'so', 'much', 'so', 'bought', 'double', 'chocolate', 'and', 'wine', 'same', 'same', 'right', 'covid_'], ['so', 'we', 'have', 'new', 'housemmate', 'moving', 'into', 'our', 'place', 'tomorrow', 'and', 'get', 'this', 'text', 'from', 'one', 'of', 'my', 'current', 'housemates', 'and', 'just', 'like', 'you', 'work', 'in', 'retail', 'store', 'tho', 'you', 'can', 'easily', 'bring', 'home', 'covid', 'too', 'https', 'tco', 'nhmxepxfzh']]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cc9baa7e9e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Assign indices to each word.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mword_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0midx_to_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# print(word_to_idx['good'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-cc9baa7e9e0a>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Assign indices to each word.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mword_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0midx_to_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# print(word_to_idx['good'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Create the vocabulary.\n",
    "\n",
    "\n",
    "# vocab = list(set([w for text in train_data.keys() for w in text.split(' ')]))\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print('%d unique words found' % vocab_size)\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "# Assign indices to each word.\n",
    "word_to_idx = { w: i for i, w in enumerate(vocab) }\n",
    "idx_to_word = { i: w for i, w in enumerate(vocab) }\n",
    "# print(word_to_idx['good'])\n",
    "# print(idx_to_word[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createInputs(text):\n",
    "  '''\n",
    "  Returns an array of one-hot vectors representing the words in the input text string.\n",
    "  - text is a string\n",
    "  - Each one-hot vector has shape (vocab_size, 1)\n",
    "  '''\n",
    "  inputs = []\n",
    "  for w in text.split(' '):\n",
    "    v = np.zeros((vocab_size, 1))\n",
    "    v[word_to_idx[w]] = 1\n",
    "    inputs.append(v)\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rnn.RNN'>\n"
     ]
    }
   ],
   "source": [
    "def softmax(xs):\n",
    "  # Applies the Softmax Function to the input array.\n",
    "  return np.exp(xs) / sum(np.exp(xs))\n",
    "\n",
    "# Initialize our RNN!\n",
    "rnn = RNN(vocab_size, 2)\n",
    "print(type(rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(data, backprop=True):\n",
    "  '''\n",
    "  Returns the RNN's loss and accuracy for the given data.\n",
    "  - data is a dictionary mapping text to True or False.\n",
    "  - backprop determines if the backward phase should be run.\n",
    "  '''\n",
    "  items = list(data.items())\n",
    "  random.shuffle(items)\n",
    "\n",
    "  loss = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for x, y in items:\n",
    "    inputs = createInputs(x)\n",
    "    target = int(y)\n",
    "\n",
    "    # Forward\n",
    "    out, _ = rnn.forward(inputs)\n",
    "    probs = softmax(out)\n",
    "\n",
    "    # Calculate loss / accuracy\n",
    "    loss -= np.log(probs[target])\n",
    "    num_correct += int(np.argmax(probs) == target)\n",
    "\n",
    "    if backprop:\n",
    "      # Build dL/dy\n",
    "      d_L_d_y = probs\n",
    "      d_L_d_y[target] -= 1\n",
    "\n",
    "      # Backward\n",
    "      rnn.backprop(d_L_d_y)\n",
    "\n",
    "  return loss / len(data), num_correct / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 100\n",
      "Train:\tLoss 0.688 | Accuracy: 0.552\n",
      "Test:\tLoss 0.696 | Accuracy: 0.500\n",
      "--- Epoch 200\n",
      "Train:\tLoss 0.672 | Accuracy: 0.638\n",
      "Test:\tLoss 0.723 | Accuracy: 0.550\n",
      "--- Epoch 300\n",
      "Train:\tLoss 0.606 | Accuracy: 0.638\n",
      "Test:\tLoss 0.722 | Accuracy: 0.500\n",
      "--- Epoch 400\n",
      "Train:\tLoss 0.400 | Accuracy: 0.810\n",
      "Test:\tLoss 0.703 | Accuracy: 0.650\n",
      "--- Epoch 500\n",
      "Train:\tLoss 0.303 | Accuracy: 0.897\n",
      "Test:\tLoss 0.683 | Accuracy: 0.600\n",
      "--- Epoch 600\n",
      "Train:\tLoss 0.115 | Accuracy: 0.966\n",
      "Test:\tLoss 0.285 | Accuracy: 0.900\n",
      "--- Epoch 700\n",
      "Train:\tLoss 0.008 | Accuracy: 1.000\n",
      "Test:\tLoss 0.029 | Accuracy: 1.000\n",
      "--- Epoch 800\n",
      "Train:\tLoss 0.004 | Accuracy: 1.000\n",
      "Test:\tLoss 0.015 | Accuracy: 1.000\n",
      "--- Epoch 900\n",
      "Train:\tLoss 0.002 | Accuracy: 1.000\n",
      "Test:\tLoss 0.013 | Accuracy: 1.000\n",
      "--- Epoch 1000\n",
      "Train:\tLoss 0.002 | Accuracy: 1.000\n",
      "Test:\tLoss 0.008 | Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "  train_loss, train_acc = processData(train_data)\n",
    "\n",
    "  if epoch % 100 == 99:\n",
    "    print('--- Epoch %d' % (epoch + 1))\n",
    "    print('Train:\\tLoss %.3f | Accuracy: %.3f' % (train_loss, train_acc))\n",
    "\n",
    "    test_loss, test_acc = processData(test_data, backprop=False)\n",
    "    print('Test:\\tLoss %.3f | Accuracy: %.3f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
