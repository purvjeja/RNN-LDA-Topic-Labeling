{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_data(stop_word_removal='no'):\n",
    "    file_contents = []\n",
    "    with open('C:/Users/hp/Desktop/finalyear/RNN-LDA-Topic-Labeling/Initiation-practice/CSV/T.csv') as f:\n",
    "        file_contents = f.read()\n",
    "    text = []\n",
    "    for val in file_contents.split('.'):\n",
    "        sent = re.findall(\"[A-Za-z]+\", val)\n",
    "        line = ''\n",
    "        for words in sent:\n",
    "            \n",
    "            if stop_word_removal == 'yes': \n",
    "                if len(words) > 1 and words not in stop_words:\n",
    "                    line = line + ' ' + words\n",
    "            else:\n",
    "                if len(words) > 1 :\n",
    "                    line = line + ' ' + words\n",
    "        text.append(line)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_dictinoary_data(text):\n",
    "    word_to_index= dict()\n",
    "    index_to_word = dict()\n",
    "    corpus = []\n",
    "    count = 0\n",
    "    vocab_size = 0\n",
    "    \n",
    "    for row in text:\n",
    "        for word in row.split():\n",
    "            word = word.lower()\n",
    "            corpus.append(word)\n",
    "            if word_to_index.get(word) == None:\n",
    "                word_to_index.update ( {word : count})\n",
    "                index_to_word.update ( {count : word })\n",
    "                count  += 1\n",
    "    vocab_size = len(word_to_index)\n",
    "    length_of_corpus = len(corpus)\n",
    "    \n",
    "    return word_to_index,index_to_word,corpus,vocab_size,length_of_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_one_hot_vectors(target_word,context_words,vocab_size,word_to_index):\n",
    "    \n",
    "    #Create an array of size = vocab_size filled with zeros\n",
    "    trgt_word_vector = np.zeros(vocab_size)\n",
    "    \n",
    "    #Get the index of the target_word according to the dictionary word_to_index. \n",
    "    #If target_word = best, the index according to the dictionary word_to_index is 0. \n",
    "    #So the one hot vector will be [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    index_of_word_dictionary = word_to_index.get(target_word) \n",
    "    \n",
    "    #Set the index to 1\n",
    "    trgt_word_vector[index_of_word_dictionary] = 1\n",
    "    \n",
    "    #Repeat same steps for context_words but in a loop\n",
    "    ctxt_word_vector = np.zeros(vocab_size)\n",
    "    \n",
    "    \n",
    "    for word in context_words:\n",
    "        index_of_word_dictionary = word_to_index.get(word) \n",
    "        ctxt_word_vector[index_of_word_dictionary] = 1\n",
    "        \n",
    "    return trgt_word_vector,ctxt_word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(corpus,window_size,vocab_size,word_to_index,length_of_corpus,sample=None):\n",
    "\n",
    "    training_data =  []\n",
    "    training_sample_words =  []\n",
    "    for i,word in enumerate(corpus):\n",
    "\n",
    "        index_target_word = i\n",
    "        target_word = word\n",
    "        context_words = []\n",
    "\n",
    "        #when target word is the first word\n",
    "        if i == 0:  \n",
    "\n",
    "            # trgt_word_index:(0), ctxt_word_index:(1,2)\n",
    "            context_words = [corpus[x] for x in range(i + 1 , window_size + 1)] \n",
    "\n",
    "\n",
    "        #when target word is the last word\n",
    "        elif i == len(corpus)-1:\n",
    "\n",
    "            # trgt_word_index:(9), ctxt_word_index:(8,7), length_of_corpus = 10\n",
    "            context_words = [corpus[x] for x in range(length_of_corpus - 2 ,length_of_corpus -2 - window_size  , -1 )]\n",
    "\n",
    "        #When target word is the middle word\n",
    "        else:\n",
    "\n",
    "            #Before the middle target word\n",
    "            before_target_word_index = index_target_word - 1\n",
    "            for x in range(before_target_word_index, before_target_word_index - window_size , -1):\n",
    "                if x >=0:\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "            #After the middle target word\n",
    "            after_target_word_index = index_target_word + 1\n",
    "            for x in range(after_target_word_index, after_target_word_index + window_size):\n",
    "                if x < len(corpus):\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "\n",
    "        trgt_word_vector,ctxt_word_vector = get_one_hot_vectors(target_word,context_words,vocab_size,word_to_index)\n",
    "        training_data.append([trgt_word_vector,ctxt_word_vector])   \n",
    "        \n",
    "        if sample is not None:\n",
    "            training_sample_words.append([target_word,context_words])   \n",
    "        \n",
    "    return training_data,training_sample_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(weight_inp_hidden,weight_hidden_output,target_word_vector):\n",
    "    \n",
    "    #target_word_vector = x , weight_inp_hidden =  weights for input layer to hidden layer  \n",
    "    hidden_layer = np.dot(weight_inp_hidden.T, target_word_vector)\n",
    "    \n",
    "    #weight_hidden_output = weights for hidden layer to output layer\n",
    "    u = np.dot(weight_hidden_output.T, hidden_layer)\n",
    "    \n",
    "    y_predicted = softmax(u)\n",
    "    \n",
    "    return y_predicted, hidden_layer, u\n",
    "  \n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_error(y_pred,context_words):\n",
    "    \n",
    "    total_error = [None] * len(y_pred)\n",
    "    index_of_1_in_context_words = {}\n",
    "    \n",
    "    for index in np.where(context_words == 1)[0]:\n",
    "        index_of_1_in_context_words.update ( {index : 'yes'} )\n",
    "        \n",
    "    number_of_1_in_context_vector = len(index_of_1_in_context_words)\n",
    "    \n",
    "    for i,value in enumerate(y_pred):\n",
    "        \n",
    "        if index_of_1_in_context_words.get(i) != None:\n",
    "            total_error[i]= (value-1) + ( (number_of_1_in_context_vector -1) * value)\n",
    "        else:\n",
    "            total_error[i]= (number_of_1_in_context_vector * value)\n",
    "            \n",
    "            \n",
    "    return  np.array(total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(weight_inp_hidden,weight_hidden_output,total_error, hidden_layer, target_word_vector,learning_rate):\n",
    "    \n",
    "    dl_weight_inp_hidden = np.outer(target_word_vector, np.dot(weight_hidden_output, total_error.T))\n",
    "    dl_weight_hidden_output = np.outer(hidden_layer, total_error)\n",
    "    \n",
    "    # Update weights\n",
    "    weight_inp_hidden = weight_inp_hidden - (learning_rate * dl_weight_inp_hidden)\n",
    "    weight_hidden_output = weight_hidden_output - (learning_rate * dl_weight_hidden_output)\n",
    "    \n",
    "    return weight_inp_hidden,weight_hidden_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(u,ctx):\n",
    "    \n",
    "    sum_1 = 0\n",
    "    for index in np.where(ctx==1)[0]:\n",
    "        sum_1 = sum_1 + u[index]\n",
    "    \n",
    "    sum_1 = -sum_1\n",
    "    sum_2 = len(np.where(ctx==1)[0]) * np.log(np.sum(np.exp(u)))\n",
    "    \n",
    "    total_loss = sum_1 + sum_2\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
